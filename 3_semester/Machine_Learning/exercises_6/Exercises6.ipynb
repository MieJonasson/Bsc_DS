{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: Logistic regression and classification\n",
    "\n",
    "You will be pleased to find that the framework for logistic regression is very similar to that of the linear regression. For this exercise we use the `GLM` method in the statsmodels library (https://www.statsmodels.org/stable/glm.html), in which we specify the model via the model matrix `X`. There is also an equivalent method, `glm`, that allows specification via the formula API just as for linear regression. The sklearn library has also a `LogisticRegression` method, but note that it by default regularizes the estimated coefficients using an L2-penalty. To run a classical logistic regression with parameters estimated by maximum likelihood, you will need to set `penalty = 'none'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from math import log, sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting familiar with the model\n",
    "\n",
    "### Translation between log-odds and probabilities\n",
    "\n",
    "\n",
    "Implement the standard logistic function `sigma` as well as its inverse, the logit function. Make a plot of `sigma`\n",
    "\n",
    "Explain how these two functions are used to transform a probability into log-odds and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = lambda eta : (math.e**eta) / (1 + math.e**eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = lambda p : log((p)/(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(-6,6),[sigma(i) for i in range(-6,6)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-odds of probability function gives us eta in the end\n",
    "# p(X) = sigma(X) -> odds = p(X)/(1-p(X)) = e^eta -> log-odds = eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a logistic regression model with a single feature $X$ where $\\beta_0=0.3$ and $\\beta_1=0.7$. \n",
    "\n",
    "A) What is the probability of Y=1 when X=5?\n",
    "\n",
    "B) What are the odds of Y=1 for X=5?\n",
    "\n",
    "C) What is the *odds ratio* comparing odds of Y=1 when X=8 to the odds when X=5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of Y=1 when X=5 is: 0.9781187290638695\n"
     ]
    }
   ],
   "source": [
    "b0 = 0.3\n",
    "b1 = 0.7\n",
    "prob = sigma(b0 + b1*5)\n",
    "print(f'probability of Y=1 when X=5 is: {prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds of Y=1 when X=5 is: 3.8000000000000007\n"
     ]
    }
   ],
   "source": [
    "odds = logit(prob)\n",
    "print(f'Odds of Y=1 when X=5 is: {odds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds Ration of X=8 compared to X=5: 1.5526315789473666\n",
      "I.e. X=8 is 1.5 times more likely to have Y=1 compared to X=5\n"
     ]
    }
   ],
   "source": [
    "odds2 = logit(sigma(b0+b1*8))\n",
    "print(f'Odds Ration of X=8 compared to X=5: {odds2/odds}')\n",
    "print('I.e. X=8 is 1.5 times more likely to have Y=1 compared to X=5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Load the `Default` data set from the ISLwR book, which is a simulated data set containing information on ten thousand customers. We will recreate the results in section 4.3. The aim with the data is to predict which customers will default on their credit card debt.\n",
    "\n",
    "`default`: A binary variable with levels No and Yes indicating whether the customer defaulted on their debt.\n",
    "\n",
    "`student` A factor with levels No and Yes indicating whether the customer is a student\n",
    "\n",
    "`balance` The average balance that the customer has remaining on their credit card after making their monthly payment\n",
    "\n",
    "`income` Income of customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income\n",
       "0      No      No   729.526495  44361.625074\n",
       "1      No     Yes   817.180407  12106.134700\n",
       "2      No      No  1073.549164  31767.138947\n",
       "3      No      No   529.250605  35704.493935\n",
       "4      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Default.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into a training set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Permutation of indices and split into train/test on 70/30 split\n",
    "shuffle = list(np.random.permutation(data.shape[0]))\n",
    "train_idx = shuffle[:int(len(shuffle)*0.7)]\n",
    "test_idx = shuffle[int(len(shuffle)*0.7):]\n",
    "# Slicing the data!\n",
    "train_data = data.iloc[train_idx]\n",
    "test_data = data.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the logistic regression\n",
    "\n",
    "A logistic regression model is specified as\n",
    "\n",
    "`sm.GLM(y, X, family=sm.families.Binomial(link = sm.families.links.logit()))`\n",
    "\n",
    "Here we have specified\n",
    "1. the outcome variable Y\n",
    "2. the model matrix X, which specifies how features enter the model\n",
    "3. the *family* of distributions for Y, which is the *binomial distribution*\n",
    "4. the *link function*, which is the *logit* for performing logistic regression. This link function is the default for the binomial, so we can leave it out.\n",
    "\n",
    "As for linear regression, the model is fitted with the `fit` method. From the resulting object you can obtain parameters and the fitted values on the training data. You predict with `predict` method and you can see the output via `summary` method.\n",
    "\n",
    "Fit a logistic regression model, `M1`, that has `balance` as the only feature, and check your results against Table 4.1 in ISLwR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.GLM(np.asarray(train_data['default']), np.asarray(train_data[['balance']]), \n",
    "    family=sm.families.Binomial(link = sm.families.links.logit()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"float\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jonas\\Desktop\\DataScienceBachelor\\3_semester\\Machine_Learning\\exercises_6\\Exercises6.ipynb Cell 18\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jonas/Desktop/DataScienceBachelor/3_semester/Machine_Learning/exercises_6/Exercises6.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1075\u001b[0m, in \u001b[0;36mGLM.fit\u001b[1;34m(self, start_params, maxiter, method, tol, scale, cov_type, cov_kwds, use_t, full_output, disp, max_start_irls, **kwargs)\u001b[0m\n\u001b[0;32m   1073\u001b[0m     \u001b[39mif\u001b[39;00m cov_type\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39meim\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1074\u001b[0m         cov_type \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnonrobust\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m-> 1075\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_irls(start_params\u001b[39m=\u001b[39mstart_params, maxiter\u001b[39m=\u001b[39mmaxiter,\n\u001b[0;32m   1076\u001b[0m                           tol\u001b[39m=\u001b[39mtol, scale\u001b[39m=\u001b[39mscale, cov_type\u001b[39m=\u001b[39mcov_type,\n\u001b[0;32m   1077\u001b[0m                           cov_kwds\u001b[39m=\u001b[39mcov_kwds, use_t\u001b[39m=\u001b[39muse_t, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1078\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1079\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optim_hessian \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39moptim_hessian\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1183\u001b[0m, in \u001b[0;36mGLM._fit_irls\u001b[1;34m(self, start_params, maxiter, tol, scale, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[0;32m   1181\u001b[0m \u001b[39mif\u001b[39;00m start_params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1182\u001b[0m     start_params \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m-> 1183\u001b[0m     mu \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfamily\u001b[39m.\u001b[39;49mstarting_mu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendog)\n\u001b[0;32m   1184\u001b[0m     lin_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfamily\u001b[39m.\u001b[39mpredict(mu)\n\u001b[0;32m   1185\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\statsmodels\\genmod\\families\\family.py:901\u001b[0m, in \u001b[0;36mBinomial.starting_mu\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstarting_mu\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[0;32m    897\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    898\u001b[0m \u001b[39m    The starting values for the IRLS algorithm for the Binomial family.\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[39m    A good choice for the binomial family is :math:`\\mu_0 = (Y_i + 0.5)/2`\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mreturn\u001b[39;00m (y \u001b[39m+\u001b[39;49m \u001b[39m.5\u001b[39;49m)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
     ]
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the exact same model, but using `LogisticRegression` from sklearn, taking care that you turn off regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1189.15893364 1035.552944    592.04518161 ... 1772.85548375  426.6935421\n  967.44157378].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jonas\\Desktop\\DataScienceBachelor\\3_semester\\Machine_Learning\\exercises_6\\Exercises6.ipynb Cell 20\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jonas/Desktop/DataScienceBachelor/3_semester/Machine_Learning/exercises_6/Exercises6.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_sklearn \u001b[39m=\u001b[39m LogisticRegression(penalty\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnone\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(train_data[\u001b[39m'\u001b[39;49m\u001b[39mbalance\u001b[39;49m\u001b[39m'\u001b[39;49m], train_data[\u001b[39m'\u001b[39;49m\u001b[39mdefault\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1505\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1506\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m-> 1508\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1509\u001b[0m     X,\n\u001b[0;32m   1510\u001b[0m     y,\n\u001b[0;32m   1511\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1512\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[0;32m   1513\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1514\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1515\u001b[0m )\n\u001b[0;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1517\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    965\u001b[0m     X,\n\u001b[0;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    967\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m    968\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    969\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m    970\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    971\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    972\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m    973\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m    974\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m    975\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    977\u001b[0m )\n\u001b[0;32m    979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:769\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    768\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 769\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    770\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    771\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    772\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    773\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    774\u001b[0m         )\n\u001b[0;32m    776\u001b[0m \u001b[39m# make sure we actually converted to numeric:\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mOUSV\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1189.15893364 1035.552944    592.04518161 ... 1772.85548375  426.6935421\n  967.44157378].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "model_sklearn = LogisticRegression(penalty='none').fit(train_data['balance'], train_data['default'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit another model, `M2`, that takes a single *categorical* feature, `student`, and check the results against Table 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a model, `M3`, that has an interaction between `student` and `balance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the three models, write down the formula for the estimated probabilities using the estimated coefficients. Write down also the formula for the estimated log odds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction \n",
    "\n",
    "Fitted values --the mean response-- are obtained as for the linear regression. However a main difference is that the mean is not used directly as a prediction of Y. Rather, we choose a threshold $\\alpha$ and predict $Y=1$ whenever $P(Y=1|X) > \\alpha$. Usually we take $\\alpha = 0.5$, unless we specifically wish to incur a \"higher cost\" for some kinds of misclassifications.\n",
    "\n",
    "Using $\\alpha = 0.5$, compute the training error rate (proportion of wrong classifications) for models M1, M2, and M3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the test error for the three models and compare to the training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the three models by their AIC: Based on this criterion, which would you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision regions and the decision boundary between them\n",
    "\n",
    "In model M1, describe the *decision regions*, i.e. for which values of the feature (income) you would predict that an individual defaults, and for which you would predict not default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a model, `M4`, with two continuous features `income` and `balance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot of your feature space (i.e. with income and balance on the axes) as follows: \n",
    "Use the model to predict the class for each point in a fine grid over the two features. Plot the points of the grid and colour them according to class: Blue for default = Yes, Red for default = No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a quadratic term to the model and make the same plot as before. You should now obtain a non-linear decision boundary (although if you plotted against the squared feature, you would indeed get a linear boundary!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting a model\n",
    "\n",
    "A) For model M1, predict the probability of defaulting for an individual with a balance of 1,000 and for an individual with balance 2,000. Try to compute the prediction from scratch yourself as well as with the `predict` method. You should obtain the same as in section 4.3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) Considering the same two individuals, how many times higher are the odds of defaulting for the individual with low balance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) For model M2, what are the probabilities of defaulting for students and non-students respectively? You should obtain the same as in section 4.3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D) In M1, what is the interpretation of the coefficient for `balance`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E) (optional) In model M3, compute the odds-ratio comparing the odds of defaulting for a student with high balance (2,000) and a student with a low balance (1,000). Do the same for a non-student. Note that the odds ratio differs -- this is a consequence of the *interaction* term!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "059b92ebffe316512df3810dcdd9739bd5d694b60baa1e9e8136193b1cf34557"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
