{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5, Machine Learning 2022\n",
    "\n",
    "The following lab-session is adapted from those of Sections 5.3 and 6.3 in Introduction to Statistical Learning with R.\n",
    "\n",
    "### The Auto dataset\n",
    "We use the `Auto` dataset that was used as an example throughout Chapter 3 on linear regression. Here, we treat the variable `mpg` (gas miles in miles per gallon) as the response and `horsepower` as the single predictor.\n",
    "\n",
    "The data has 392 observations on the following 9 variables.\n",
    "\n",
    "`mpg` miles per gallon\n",
    "\n",
    "`cylinders` Number of cylinders between 4 and 8 displacementEngine displacement (cu. inches) \n",
    "\n",
    "`horsepower` Engine horsepower\n",
    "\n",
    "`weight` Vehicle weight (lbs.)\n",
    "\n",
    "`acceleration` Time to accelerate from 0 to 60 mph (sec.)\n",
    "\n",
    "`year` Model year (modulo 100)\n",
    "\n",
    "`origin` Origin of car (1. American, 2. European, 3. Japanese)\n",
    "\n",
    "`name` Vehicle name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import numpy as np\n",
    "from pandas import read_csv, DataFrame\n",
    "from math import log, sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from csv; change the directory as you need!\n",
    "Auto = read_csv(\"Auto.csv\")\n",
    "Auto.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It is recommended that you set a random seed, so that any results based on randomness are recreated whenever you run the notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set seed!\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The validation set approach\n",
    "\n",
    "Split the set of observations into two halves by selecting a random subset of 196 obervations out of the original 392 observations. We refer to these observations as the *training set* and the remaining observations as the *validation set*. For creating the random split, you can use `random.sample(seq, n)` to select `n` numbers without replacement from the sequence `seq`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = random.sample(range(392),196)\n",
    "train_data = Auto.iloc[train_idx]\n",
    "val_data = Auto.iloc[[i for i in range(392) if i not in train_idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a linear regression on the training set: `mpg`$= \\beta_0 + \\beta_1$ `horsepower` $+\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>34.1</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1975</td>\n",
       "      <td>15.2</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>maxda glc deluxe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>199.0</td>\n",
       "      <td>97</td>\n",
       "      <td>2774</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc hornet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>17.5</td>\n",
       "      <td>8</td>\n",
       "      <td>305.0</td>\n",
       "      <td>145</td>\n",
       "      <td>3880</td>\n",
       "      <td>12.5</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet caprice classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>19.9</td>\n",
       "      <td>8</td>\n",
       "      <td>260.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3365</td>\n",
       "      <td>15.5</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>oldsmobile cutlass salon brougham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>25.4</td>\n",
       "      <td>5</td>\n",
       "      <td>183.0</td>\n",
       "      <td>77</td>\n",
       "      <td>3530</td>\n",
       "      <td>20.1</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>mercedes benz 300d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>1940</td>\n",
       "      <td>14.5</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>volkswagen rabbit custom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>4135</td>\n",
       "      <td>13.5</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth fury iii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>79</td>\n",
       "      <td>2255</td>\n",
       "      <td>17.7</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge colt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>4077</td>\n",
       "      <td>14.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite custom (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>17.6</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>129</td>\n",
       "      <td>3725</td>\n",
       "      <td>13.4</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>ford ltd landau</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "292  34.1          4          86.0          65    1975          15.2    79   \n",
       "16   18.0          6         199.0          97    2774          15.5    70   \n",
       "219  17.5          8         305.0         145    3880          12.5    77   \n",
       "247  19.9          8         260.0         110    3365          15.5    78   \n",
       "295  25.4          5         183.0          77    3530          20.1    79   \n",
       "..    ...        ...           ...         ...     ...           ...   ...   \n",
       "231  29.0          4          97.0          78    1940          14.5    77   \n",
       "63   15.0          8         318.0         150    4135          13.5    72   \n",
       "183  26.0          4          98.0          79    2255          17.7    76   \n",
       "74   14.0          8         318.0         150    4077          14.0    72   \n",
       "284  17.6          8         302.0         129    3725          13.4    79   \n",
       "\n",
       "     origin                               name  \n",
       "292       3                   maxda glc deluxe  \n",
       "16        1                         amc hornet  \n",
       "219       1          chevrolet caprice classic  \n",
       "247       1  oldsmobile cutlass salon brougham  \n",
       "295       2                 mercedes benz 300d  \n",
       "..      ...                                ...  \n",
       "231       2           volkswagen rabbit custom  \n",
       "63        1                  plymouth fury iii  \n",
       "183       1                         dodge colt  \n",
       "74        1     plymouth satellite custom (sw)  \n",
       "284       1                    ford ltd landau  \n",
       "\n",
       "[196 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the MSE on the 196 observations that are the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now estimate also the MSE for the quadradic and cubic regressions.\n",
    "\n",
    "The ISLwR book found an estimated test MSE of (23.27, 18.27, and 18.79) for the three regression models. \n",
    "\n",
    "Set another seed and create a different split of your data - do you get different results? Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model would you choose based on the estimated MSE? \n",
    "\n",
    "If you instead train the models on the entire data and perform model selection via F-tests or AIC, would you choose differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-one-out cross-validation\n",
    "\n",
    "Implement leave-one-out cross-validation and use it to estimate the MSE for the three regression models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold cross-validation\n",
    "\n",
    "Estimate the MSE now from k-fold cross-validation that you implement yourself. If you set k=10, then you get Figure 5.6 from the book, but you are welcome to choose another k. Make sure that you properly randomise observations into the k folds! One way is to first make a random permutation of row indices and then chop the re-ordered dataset into k (roughly) even parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LOOCV estimate of the MSE can also be computed automatially with sklearn. In fact, sklearn provides a lot of functionality for cross-validation. However, our objective right now is to understand how the algorithms work, so that you learn to reflect on them and use the automatic functionality appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend your code with a for-loop that iterates over increasing orders of the polynomial (1 to 10). Note that is possible to autogenerate a design matrix with all the terms of the polynomial with functions such as `sklearn.preprocessing.PolynomialFeatures` (It should also work for several features; a degree 2 polynomial in features x1 and x2 would need  $1+x_1+x_2+x_1x_2+x_1^2+x_2^2$, i.e. also the term $x_1x_2$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the resulting MSE curve against the degree of the polynomial (this is the complexity or the flexibility). \n",
    "\n",
    "Do you get the same conclusion as before regarding your choice of model?\n",
    "\n",
    "Was it faster than LOOCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shrinkage/Regularization\n",
    "\n",
    "Now try the two shrinkage methods we saw on Friday, ridge regression and lasso. To make things a bit more exciting, include in your models all variables available in the dataset, and perhaps a few polynomial terms for `horsepower` now that you know they are relevant. The `name` variable is evidently an identifyer and should not be used as a predictor in the model.\n",
    "\n",
    "The Lasso estimates for coefficients $\\beta$ in a linear regression model are found by minimising $RSS + \\lambda\\sum_{j=1}^p|\\beta_j|$ rather than RSS. \n",
    "\n",
    "In Ridge regression, we estimate $\\beta$ by minimising $RSS + \\lambda\\sum_{j=1}^p\\beta_j^2$ rather than RSS. \n",
    "\n",
    "In both cases, we need to set the regularation parameter $\\lambda$. **The parameter $\\lambda$ is called `alpha` in the Python implementations**\n",
    "\n",
    "\n",
    "The relevant method in the statsmodel library is `fit_regularized`, which you use in place of `fit` after instantiating an ols model. If `L1_wt=1`, the fit is the lasso (L1-penalty). Ridge regression (L2-penalty) is obtained by setting `L1_wt=0`.  The reason we need to set parameter `L1_wt` is that the method actually implements the more general 'elastic net' penalty, which is a convex combination of the Lasso penalty and the ridge regression penalty with weight `L1_wt`. The fitting method returns a `RegressionResults` object, from which you can extract `params` and `fittedvalues`, and it has a `predict` method just like the usual linear regression output from ols.\n",
    "\n",
    "The sklearn libary has methods `Ridge` and `Lasso`. \n",
    "\n",
    "**Set aside a test set of about 25% of the data that you can use at the end to estimate the MSE of your final model. Use the remaining data to train the regularised regression models.**\n",
    "\n",
    "### Ridge regression\n",
    "\n",
    "First, carry out a ridge regression where the regulation parameter $\\lambda$ is fixed at 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, $\\lambda = 10$ is a rather arbitrary suggestion. We need to decide on a suitable value for the hyperparameter $\\lambda$. This we can do using a dedicated validation set, or we could do it by cross-validation. We do the latter.\n",
    "\n",
    "Take a suitable range of $\\lambda \\in [0, \\infty)$, for instance you can take a sequence $10^i, i=-2, \\ldots, 5$. Using 5-fold cross-validation to estimate the MSE (call it `MSE_lambda`) for each $\\lambda$, make a plot of how MSE changes with $\\lambda$. Based on this plot, how would you choose $\\lambda$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having chosen a $\\lambda$, would it be appropriate to report the corresponding `MSE_lambda` as the test error for the ridge regression?\n",
    "Compute the test MSE using the dedicated test set and compare to `MSE_lambda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, once we have chosen the regularisation parameter $\\lambda$, we should preferably make use of *all of the data* to (re-)train the model, and then report the associated test MSE from the test data. Do this, and inspect the model estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso\n",
    "\n",
    "Following the same procedure as for ridge regression, train a lasso regression where the regularisation parameter $\\lambda$ is selected by cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the estimated coefficients for your lasso to those from the ridge regression -- did lasso result in a more sparse model? (i.e. did it set some coefficients to zero and thus eliminate features from the model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "059b92ebffe316512df3810dcdd9739bd5d694b60baa1e9e8136193b1cf34557"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
